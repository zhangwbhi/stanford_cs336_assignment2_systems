# Model hyperparameters
vocab_size: 10000
context_length: 1024
d_model: 1024
num_layers: 24
num_heads: 16
d_ff: 4096
rope_theta: 10000.0

# Benchmarking parameters
batch_size: 4
warmup_steps: 5
repeats: 10
forward_only: False
device: "cuda"
