# Model hyperparameters
vocab_size: 1000
context_length: 128
d_model: 200
num_layers: 12
num_heads: 5
d_ff: 800
rope_theta: 10000.0

# Benchmarking parameters
batch_size: 4
warmup_steps: 0
repeats: 4
forward_only: False
device: "cuda"
